{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAML_Project_SVM_Multiclass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rDm0aLYZZ_S2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_names = ['blues', 'classical', 'country', 'disco', 'hipop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "# Dataset import\n",
        "data = pd.read_csv('extracted_dataset.csv')\n",
        "\n",
        "# Dataset normalization\n",
        "data_mean = data.mean()\n",
        "data_std = data.std()\n",
        "\n",
        "data_normalized = (data - data_mean) / data_std\n",
        "\n",
        "dataset = data_normalized.to_numpy()[:, 1:4]\n",
        "labels = data.to_numpy()[:, 4].astype(int)"
      ],
      "metadata": {
        "id": "jOR16qSHaTAy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Separation of the training set and the validation set**"
      ],
      "metadata": {
        "id": "hFOuOTBabtSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Indexes extraction\n",
        "indexes_train = np.random.choice(1000, 800, replace=False)\n",
        "indexes_valid= np.setdiff1d(np.array([i for i in range(1000)]), indexes_train)\n",
        "\n",
        "dataset_train = dataset[indexes_train, :]\n",
        "dataset_valid = dataset[indexes_valid, :]\n",
        "\n",
        "labels_train = labels[indexes_train]\n",
        "labels_valid = labels[indexes_valid]"
      ],
      "metadata": {
        "id": "hgXCU4hOb2nW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Primal linear boundary**"
      ],
      "metadata": {
        "id": "ZhOm8GmydRlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = 0.001\n",
        "learning_rate = 0.02\n",
        "\n",
        "w = np.random.randn(3)\n",
        "b = 0"
      ],
      "metadata": {
        "id": "gU9FEMWAdQ2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(x):\n",
        "  return (np.dot(w, x) - b)\n",
        "\n",
        "def hingeloss(x, y):\n",
        "  prod = y * classify(x)\n",
        "\n",
        "  if prod >= 1: return 0\n",
        "  else: return 1-prod\n",
        "\n",
        "def hinge_derivative_w(x, y):\n",
        "  prod = y * classify(x)\n",
        "  prod_elem = y * x\n",
        "  if prod >= 1: return np.zeros(x.shape[0])\n",
        "  else: return -prod_elem\n",
        "\n",
        "def hinge_derivative_b(x, y):\n",
        "  prod = y * classify(x)\n",
        "  if prod >= 1: return 0\n",
        "  else: return y"
      ],
      "metadata": {
        "id": "LlNQsDwFdlBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "sE9hsvdsd1kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_loss = list()\n",
        "loss = 0\n",
        "\n",
        "for epoch in range(1000):\n",
        "  gradient_w = np.zeros(w.size)\n",
        "  gradient_b = 0\n",
        "\n",
        "  for sample_index in range(100):\n",
        "    gradient_w += hinge_derivative_w(class1_data[sample_index,:], 1)\n",
        "    gradient_w += hinge_derivative_w(class2_data[sample_index,:], -1)\n",
        "    gradient_b += hinge_derivative_b(class1_data[sample_index,:], 1)\n",
        "    gradient_b += hinge_derivative_b(class2_data[sample_index,:], -1)\n",
        "\n",
        "  gradient_w /= 200.0\n",
        "  gradient_b /= 200.0\n",
        "\n",
        "  w = w - learning_rate * gradient_w\n",
        "  b = b - learning_rate * gradient_b\n",
        "\n",
        "  loss=0\n",
        "  for sample_index in range(100):\n",
        "    loss += hingeloss(class1_data[sample_index,:], 1)\n",
        "    loss += hingeloss(class2_data[sample_index,:], -1)\n",
        "\n",
        "  history_loss.append(loss/200)\n",
        "\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "fig, axs = plt.subplots(figsize = (16,8))\n",
        "\n",
        "axs.semilogy(history_loss)"
      ],
      "metadata": {
        "id": "iQJ76zqEdzs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion matrix**"
      ],
      "metadata": {
        "id": "S0hEZzSUeQAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#da fare"
      ],
      "metadata": {
        "id": "bHlKx8yxePm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Primal with quadratic feature map"
      ],
      "metadata": {
        "id": "P7l7AXBAegwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def phi(x):\n",
        "  f1 = x[0]\n",
        "  f2 = x[1]\n",
        "  f3 = x[2]\n",
        "  return np.array([f1, f2, f3, f1**2, f2**2, f3**2, f1*f2, f2*f3, f1*f3])"
      ],
      "metadata": {
        "id": "sU-MIN8Megi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_size = 9\n",
        "w = np.zeros(feature_size)\n",
        "b = 0\n",
        "\n",
        "history_loss = list()\n",
        "loss = 0\n",
        "\n",
        "for epoch in range(10000):\n",
        "  gradient_w = np.zeros(w.size)\n",
        "  gradient_b = 0\n",
        "  for sample_index in range(100):\n",
        "    phi_1 = phi(class1_data[sample_index,:])\n",
        "    phi_2 = phi(class2_data[sample_index,:])\n",
        "    gradient_w += hinge_derivative_w(phi_1, 1)\n",
        "    gradient_w += hinge_derivative_w(phi_2, -1)\n",
        "    gradient_b += hinge_derivative_b(phi_1, 1)\n",
        "    gradient_b += hinge_derivative_b(phi_2, -1)\n",
        "  gradient_w /= 200.0\n",
        "  gradient_b /= 200.0\n",
        "  \n",
        "  w = w - learning_rate * gradient_w\n",
        "  b = b - learning_rate * gradient_b\n",
        "\n",
        "  loss=0\n",
        "  for sample_index in range(100):\n",
        "    phi_1 = phi(class1_data[sample_index,:])\n",
        "    phi_2 = phi(class2_data[sample_index,:])\n",
        "    loss += hingeloss(phi_1, 1)\n",
        "    loss += hingeloss(phi_2, -1)\n",
        "\n",
        "  history_loss.append(loss/200)\n",
        "\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "fig, axs = plt.subplots(figsize = (16,8))\n",
        "\n",
        "axs.semilogy(history_loss)"
      ],
      "metadata": {
        "id": "z-iHJ4cAezIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dual with linear margin**"
      ],
      "metadata": {
        "id": "-sn6U6t6e-H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import scipy.optimize as opt"
      ],
      "metadata": {
        "id": "kS_oBj7XfDZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hessian(x):\n",
        "  return np.zeros((200, 200))\n",
        "\n",
        "def lag(c):\n",
        "  partial_1 = - jnp.sum(c)\n",
        "  X_1 = in_data * in_labels[:, None]\n",
        "  H = X_1 @ X_1.T\n",
        "  partial_2 = (c.T @ H @ c)/2\n",
        "  return partial_1 + partial_2"
      ],
      "metadata": {
        "id": "JJHlSjjxfGkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_initial = np.zeros(200)\n",
        "in_data = np.concatenate((class1_data, class2_data), axis=0)\n",
        "in_labels = np.concatenate((np.ones(100), -1 * np.ones(100)), axis=None)\n",
        "\n",
        "lag_jit=jax.jit(lag)\n",
        "\n",
        "linear_constraint = opt.LinearConstraint(in_labels, 0, 0, keep_feasible=True)\n",
        "res = opt.minimize(lag_jit, c_initial, method='trust-constr', jac='2-point', hess=hessian, constraints=[linear_constraint], options={'verbose': 1, 'maxiter': 10000}, bounds=opt.Bounds(np.zeros(200), np.ones(200)*np.inf))"
      ],
      "metadata": {
        "id": "-V3Antl3fTOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.array(res.x)\n",
        "\n",
        "w = np.zeros(3)\n",
        "\n",
        "for sample_index in range(200):\n",
        "  w += c[sample_index] * in_labels[sample_index] * in_data[sample_index, :]\n",
        "\n",
        "best_b = 0\n",
        "best_prec = 0\n",
        "\n",
        "for i in range(200):\n",
        "  b = np.dot(w, in_data[i, :] - in_labels[i])\n",
        "  confusion_mat = np.zeros((2,2))\n",
        "  for test_index in range(100):\n",
        "    predicted = 0 if classify(class1_data[test_index,:]) >= 0 else 1\n",
        "    confusion_mat[0,predicted] += 1\n",
        "    predicted = 0 if classify(class2_data[test_index,:]) >= 0 else 1\n",
        "    confusion_mat[1,predicted] += 1\n",
        "    prec = confusion_mat.trace() / confusion_mat.sum()\n",
        "    if best_prec < prec:\n",
        "      best_prec = prec\n",
        "      best_b = b"
      ],
      "metadata": {
        "id": "_thM4-uDfYgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dual with kernel trick"
      ],
      "metadata": {
        "id": "mgAzHNcOf6Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kernel_mat(xi, xj):\n",
        "  return (jnp.dot(xi, xj) + np.ones((N, N)))**3\n",
        "\n",
        "def kernel_vec(xi, xj):\n",
        "  return (np.dot(xi, xj) + 1)**3\n",
        "\n",
        "def lag_kernel(c):\n",
        "  partial_1 = -jnp.sum(c)\n",
        "\n",
        "  c_outer = jnp.outer(c, c)\n",
        "  c_outer = jnp.triu(c_outer)\n",
        "\n",
        "  y_outer = jnp.outer(in_labels, in_labels)\n",
        "  y_outer = jnp.triu(y_outer)\n",
        "\n",
        "  K= kernel_mat(in_data, in_data.T)\n",
        "\n",
        "  partial_2= 0.5 * jnp.sum(c_outer * y_outer * K)\n",
        "\n",
        "  return partial_1 + partial_2"
      ],
      "metadata": {
        "id": "if_AotWvf9Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lag_k_jit=jax.jit(lag_kernel)\n",
        "\n",
        "linear_constraint = opt.LinearConstraint(in_labels, 0, 0, keep_feasible=True)\n",
        "res = opt.minimize(lag_k_jit, a, method='trust-constr', jac='2-point', hess=hessian, constraints=[linear_constraint], options={'verbose': 1, 'maxiter': 1000}, bounds=opt.Bounds(np.zeros(200), np.ones(200)*np.inf))"
      ],
      "metadata": {
        "id": "HrviUyargHYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.array(res.x)\n",
        "w_phi = np.zeros(N)\n",
        "\n",
        "index_non_zero = -1\n",
        "for j in range(N):\n",
        "  #NB: valid e training\n",
        "  w_phi[j] = np.sum(np.array([c[i]*in_labels[i]*kernel_vec(valid[j, :], training[i, :]) for i in range(N)]))\n",
        "  if c[j]>0 and index_non_zero<0:\n",
        "    index_non_zero = j\n",
        "\n",
        "b = - in_labels[index_non_zero] + w_phi[index_non_zero]"
      ],
      "metadata": {
        "id": "H6eFQnPOgM1p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}