{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAML_Project_SVM_Multiclass_OneToOne.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDm0aLYZZ_S2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_names = ['blues', 'classical', 'country', 'disco', 'hipop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "# Dataset import\n",
        "data = pd.read_csv('extracted_dataset.csv')\n",
        "\n",
        "# Dataset normalization\n",
        "data_mean = data.mean()\n",
        "data_std = data.std()\n",
        "\n",
        "data_normalized = (data - data_mean) / data_std\n",
        "\n",
        "dataset = data_normalized.to_numpy()[:, 1:4]\n",
        "labels = data.to_numpy()[:, 4].astype(int)"
      ],
      "metadata": {
        "id": "jOR16qSHaTAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Separation of the training set and the validation set**"
      ],
      "metadata": {
        "id": "hFOuOTBabtSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Indexes extraction\n",
        "indices = np.random.choice(1000, 1000, replace = False)\n",
        "N_train = 800\n",
        "\n",
        "indices_train = indices[:N_train]\n",
        "indices_valid = indices[N_train:]\n",
        "\n",
        "dataset_train = dataset[indices_train, :]\n",
        "dataset_valid = dataset[indices_valid, :]\n",
        "\n",
        "labels_train = labels[indices_train]\n",
        "labels_valid = labels[indices_valid]"
      ],
      "metadata": {
        "id": "hgXCU4hOb2nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Primal linear boundary**"
      ],
      "metadata": {
        "id": "ZhOm8GmydRlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SVMClassifier:\n",
        "  def __init__(self, genre1, genre2):\n",
        "    self.genre1 = genre1 # Corresponds to SVM label 1\n",
        "    self.genre2 = genre2 # Corresponds to SVM label -1\n",
        "\n",
        "  @abstractmethod\n",
        "  def bin_classify(self, input):\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def train(self, x, y):\n",
        "    pass"
      ],
      "metadata": {
        "id": "TNvbvKQCUerS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrimalLinearClassifier(SVMClassifier):\n",
        "  def __init__(self, genre1, genre2):\n",
        "    super().__init__(genre1, genre2)\n",
        "    self.w = np.random.randn(3)\n",
        "    self.b = 0\n",
        "    self.learning_rate = 0.02\n",
        "    self.num_epochs = 100\n",
        "\n",
        "  def bin_classify(self, input):\n",
        "    return self.genre1 if classify(input) >= 0 else self.genre2\n",
        "\n",
        "  def train(self, x, y):\n",
        "    class1_data = x[y == genre_names.index(genre1)]\n",
        "    class2_data = x[y == genre_names.index(genre2)]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      gradient_w = np.zeros(w.size)\n",
        "      gradient_b = 0\n",
        "\n",
        "      for sample_index in range(100):\n",
        "        gradient_w += hinge_derivative_w(class1_data[sample_index,:], 1)\n",
        "        gradient_w += hinge_derivative_w(class2_data[sample_index,:], -1)\n",
        "        gradient_b += hinge_derivative_b(class1_data[sample_index,:], 1)\n",
        "        gradient_b += hinge_derivative_b(class2_data[sample_index,:], -1)\n",
        "\n",
        "      gradient_w /= 200.0\n",
        "      gradient_b /= 200.0\n",
        "\n",
        "    w = w - learning_rate * gradient_w\n",
        "    b = b - learning_rate * gradient_b\n",
        "\n",
        "  def set_learning_rate(self, val):\n",
        "    self.learning_rate = val\n",
        "\n",
        "  def set_num_epochs(self, val):\n",
        "    self.num_epochs = val\n",
        "\n",
        "\n",
        "  # Utils\n",
        "  def internal_classify(x):\n",
        "    return (np.dot(w, x) - b)\n",
        "\n",
        "  def hingeloss(x, y):\n",
        "    prod = y * classify(x)\n",
        "\n",
        "    if prod >= 1: return 0\n",
        "    else: return 1-prod\n",
        "\n",
        "  def hinge_derivative_w(x, y):\n",
        "    prod = y * classify(x)\n",
        "    prod_elem = y * x\n",
        "    if prod >= 1: return np.zeros(x.shape[0])\n",
        "    else: return -prod_elem\n",
        "\n",
        "  def hinge_derivative_b(x, y):\n",
        "    prod = y * classify(x)\n",
        "    if prod >= 1: return 0\n",
        "    else: return y"
      ],
      "metadata": {
        "id": "A1buiHsaSWCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DBT_Node:\n",
        "  def __init()__(self, genre1, genre2, classifier):\n",
        "    self.genre1 = genre1\n",
        "    self.genre2 = genre2\n",
        "    self.classifier = classifier\n",
        "\n",
        "    self.left_child = None\n",
        "    self.right_child = None\n",
        "\n",
        "  def is_leaf(self):\n",
        "    return self.left_child == None and self.right_child == None\n",
        "\n",
        "  def classify(self, input):\n",
        "    pred_genre = self.classifier.bin_classify(input)\n",
        "    \n",
        "    if self.is_leaf():\n",
        "      return pred_genre\n",
        "    else\n",
        "      if pred_genre == genre1:\n",
        "        return self.left_child.classify(input)\n",
        "      else\n",
        "        return self.right_child.classify(input)"
      ],
      "metadata": {
        "id": "cYI105sScynJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionBinaryTree:\n",
        "  def __init__(self, genres, genre_classifiers):\n",
        "    curr_classifier = find_classifier(genres[0], genres[1], genre_classifiers)\n",
        "\n",
        "    self.root = DBT_Node(genres[0], genres[1], curr_classifier)\n",
        "\n",
        "    build_tree(genres, genre_classifiers, self.root)\n",
        "\n",
        "  def classify(self, input):\n",
        "    return self.root.classify(input)\n",
        "\n",
        "  \n",
        "  # Utils\n",
        "  \"\"\"\n",
        "  Recursively constructs the binary decision tree\n",
        "  \"\"\"\n",
        "  def build_tree(self, genres, genre_classifiers, root):\n",
        "    if len(genres) == 2:\n",
        "      return\n",
        "    \n",
        "    # Remove the genre that has already been discarded if the left choice is made\n",
        "    left_genres = genres.copy()\n",
        "    left_genres.remove(root.genre2)\n",
        "    # Remove its classifiers\n",
        "    left_classifiers = find_all_classifiers_except(root.genre2, genre_classifiers)\n",
        "\n",
        "    # Find the classifier for the left child and create the node\n",
        "    curr_classifier = find_classifier(root.genre1, left_genres[1], genre_classifiers)\n",
        "    root.left_child = DBT_Node(root.genre1, left_genres[1], curr_classifier)\n",
        "    \n",
        "    # Continue building the tree with the left child\n",
        "    self.build_tree(left_genres, left_classifiers, root.left_child)\n",
        "\n",
        "\n",
        "    # Remove the genre that has already been discarded if the left choice is made\n",
        "    right_genres = genres.copy()\n",
        "    right_genres.remove(root.genre1)\n",
        "    # Remove its classifiers\n",
        "    right_classifiers = find_all_classifiers_except(root.genre1, genre_classifiers)\n",
        "\n",
        "    # Find the classifier for the left child and create the node\n",
        "    curr_classifier = find_classifier(root.genre2, right_genres[1], genre_classifiers)\n",
        "    root.right_child = DBT_Node(root.genre1, right_genres[1], curr_classifier)\n",
        "    \n",
        "    # Continue building the tree with the left child\n",
        "    self.build_tree(right_genres, right_classifiers, root.right_child)  \n",
        "\n",
        "    \n",
        "  \"\"\"\n",
        "  Finds the binary classifier between gen_a and gen_b\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def find_classifier(gen_a, gen_b, classifiers):\n",
        "    buffer = None\n",
        "\n",
        "    for classifier in self.classifiers:\n",
        "      if (classifier.genre1 == gen_a and classifier.genre2 == gen_b) or (classifier.genre1 == gen_b and classifier.genre2 == gen_a):\n",
        "        buffer = classifier\n",
        "        break\n",
        "\n",
        "    # There should be a classifier for each couple\n",
        "    if buffer == None:\n",
        "      raise KeyError('No classifier was found for {} and {}'.format(gen_a, gen_b))\n",
        "    \n",
        "    return buffer\n",
        "\n",
        "  \"\"\"\n",
        "  Finds all binary classifiers with specified genre\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def find_all_classifier(genre, classifiers):\n",
        "    found = list()\n",
        "\n",
        "    for classifier in self.classifiers:\n",
        "      if (classifier.genre1 == genre or classifier.genre2 == genre):\n",
        "        found.append(classifier)\n",
        "    \n",
        "    return found\n",
        "\n",
        "  \"\"\"\n",
        "  Finds all binary classifiers that do not check the excluded genre\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def find_all_classifiers_except(exclude, classifiers):\n",
        "    found = list()\n",
        "\n",
        "    for classifier in self.classifiers:\n",
        "      if classifier.genre1 != exclude and classifier.genre2 != exclude):\n",
        "        found.append(classifier)\n",
        "\n",
        "    return found"
      ],
      "metadata": {
        "id": "l5pk3jB-cVlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MulticlassSVM:\n",
        "  def __init__(self, genre_list):\n",
        "    self.active_genres = genre_list.copy()\n",
        "    self.decision_tree = None\n",
        "    \n",
        "    n_gen = len(genre_list)\n",
        "\n",
        "    self.classifiers = list()\n",
        "\n",
        "    for i in range(n_gen):\n",
        "      for j in range(i + 1, n_gen):\n",
        "        genre1 = genre_list[i]\n",
        "        genre2 = genre_list[j]\n",
        "        classifier = PrimalLinearClassifier(genre1, genre2)\n",
        "        self.classifiers.append(classifier)\n",
        "\n",
        "    def train_all(self):\n",
        "      for i, svm_classif in enumerate(self.classifiers):\n",
        "        print('Started Training for classifier {}, with genres {} and  {}'.format(i + 1, svm_classif.genre1, svm_classif.genre2))\n",
        "        svm_classif.train()\n",
        "        print('Ended Training for classifier {}, with genres {} and  {}'.format(i + 1, svm_classif.genre1, svm_classif.genre2))\n",
        "\n",
        "    def classify(self, input):\n",
        "      # classification with binary decision tree\n",
        "      pass\n",
        "      "
      ],
      "metadata": {
        "id": "UrllusRdV-82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion matrix**"
      ],
      "metadata": {
        "id": "S0hEZzSUeQAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#da fare"
      ],
      "metadata": {
        "id": "bHlKx8yxePm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Primal with quadratic feature map"
      ],
      "metadata": {
        "id": "P7l7AXBAegwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def phi(x):\n",
        "  f1 = x[0]\n",
        "  f2 = x[1]\n",
        "  f3 = x[2]\n",
        "  return np.array([f1, f2, f3, f1**2, f2**2, f3**2, f1*f2, f2*f3, f1*f3])"
      ],
      "metadata": {
        "id": "sU-MIN8Megi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_size = 9\n",
        "w = np.zeros(feature_size)\n",
        "b = 0\n",
        "\n",
        "history_loss = list()\n",
        "loss = 0\n",
        "\n",
        "for epoch in range(10000):\n",
        "  gradient_w = np.zeros(w.size)\n",
        "  gradient_b = 0\n",
        "  for sample_index in range(100):\n",
        "    phi_1 = phi(class1_data[sample_index,:])\n",
        "    phi_2 = phi(class2_data[sample_index,:])\n",
        "    gradient_w += hinge_derivative_w(phi_1, 1)\n",
        "    gradient_w += hinge_derivative_w(phi_2, -1)\n",
        "    gradient_b += hinge_derivative_b(phi_1, 1)\n",
        "    gradient_b += hinge_derivative_b(phi_2, -1)\n",
        "  gradient_w /= 200.0\n",
        "  gradient_b /= 200.0\n",
        "  \n",
        "  w = w - learning_rate * gradient_w\n",
        "  b = b - learning_rate * gradient_b\n",
        "\n",
        "  loss=0\n",
        "  for sample_index in range(100):\n",
        "    phi_1 = phi(class1_data[sample_index,:])\n",
        "    phi_2 = phi(class2_data[sample_index,:])\n",
        "    loss += hingeloss(phi_1, 1)\n",
        "    loss += hingeloss(phi_2, -1)\n",
        "\n",
        "  history_loss.append(loss/200)\n",
        "\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "fig, axs = plt.subplots(figsize = (16,8))\n",
        "\n",
        "axs.semilogy(history_loss)"
      ],
      "metadata": {
        "id": "z-iHJ4cAezIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dual with linear margin**"
      ],
      "metadata": {
        "id": "-sn6U6t6e-H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import scipy.optimize as opt"
      ],
      "metadata": {
        "id": "kS_oBj7XfDZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hessian(x):\n",
        "  return np.zeros((200, 200))\n",
        "\n",
        "def lag(c):\n",
        "  partial_1 = - jnp.sum(c)\n",
        "  X_1 = in_data * in_labels[:, None]\n",
        "  H = X_1 @ X_1.T\n",
        "  partial_2 = (c.T @ H @ c)/2\n",
        "  return partial_1 + partial_2"
      ],
      "metadata": {
        "id": "JJHlSjjxfGkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_initial = np.zeros(200)\n",
        "in_data = np.concatenate((class1_data, class2_data), axis=0)\n",
        "in_labels = np.concatenate((np.ones(100), -1 * np.ones(100)), axis=None)\n",
        "\n",
        "lag_jit=jax.jit(lag)\n",
        "\n",
        "linear_constraint = opt.LinearConstraint(in_labels, 0, 0, keep_feasible=True)\n",
        "res = opt.minimize(lag_jit, c_initial, method='trust-constr', jac='2-point', hess=hessian, constraints=[linear_constraint], options={'verbose': 1, 'maxiter': 10000}, bounds=opt.Bounds(np.zeros(200), np.ones(200)*np.inf))"
      ],
      "metadata": {
        "id": "-V3Antl3fTOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.array(res.x)\n",
        "\n",
        "w = np.zeros(3)\n",
        "\n",
        "for sample_index in range(200):\n",
        "  w += c[sample_index] * in_labels[sample_index] * in_data[sample_index, :]\n",
        "\n",
        "best_b = 0\n",
        "best_prec = 0\n",
        "\n",
        "for i in range(200):\n",
        "  b = np.dot(w, in_data[i, :] - in_labels[i])\n",
        "  confusion_mat = np.zeros((2,2))\n",
        "  for test_index in range(100):\n",
        "    predicted = 0 if classify(class1_data[test_index,:]) >= 0 else 1\n",
        "    confusion_mat[0,predicted] += 1\n",
        "    predicted = 0 if classify(class2_data[test_index,:]) >= 0 else 1\n",
        "    confusion_mat[1,predicted] += 1\n",
        "    prec = confusion_mat.trace() / confusion_mat.sum()\n",
        "    if best_prec < prec:\n",
        "      best_prec = prec\n",
        "      best_b = b"
      ],
      "metadata": {
        "id": "_thM4-uDfYgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dual with kernel trick"
      ],
      "metadata": {
        "id": "mgAzHNcOf6Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kernel_mat(xi, xj):\n",
        "  return (jnp.dot(xi, xj) + np.ones((N, N)))**3\n",
        "\n",
        "def kernel_vec(xi, xj):\n",
        "  return (np.dot(xi, xj) + 1)**3\n",
        "\n",
        "def lag_kernel(c):\n",
        "  partial_1 = -jnp.sum(c)\n",
        "\n",
        "  c_outer = jnp.outer(c, c)\n",
        "  c_outer = jnp.triu(c_outer)\n",
        "\n",
        "  y_outer = jnp.outer(in_labels, in_labels)\n",
        "  y_outer = jnp.triu(y_outer)\n",
        "\n",
        "  K= kernel_mat(in_data, in_data.T)\n",
        "\n",
        "  partial_2= 0.5 * jnp.sum(c_outer * y_outer * K)\n",
        "\n",
        "  return partial_1 + partial_2"
      ],
      "metadata": {
        "id": "if_AotWvf9Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lag_k_jit=jax.jit(lag_kernel)\n",
        "\n",
        "linear_constraint = opt.LinearConstraint(in_labels, 0, 0, keep_feasible=True)\n",
        "res = opt.minimize(lag_k_jit, a, method='trust-constr', jac='2-point', hess=hessian, constraints=[linear_constraint], options={'verbose': 1, 'maxiter': 1000}, bounds=opt.Bounds(np.zeros(200), np.ones(200)*np.inf))"
      ],
      "metadata": {
        "id": "HrviUyargHYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.array(res.x)\n",
        "w_phi = np.zeros(N)\n",
        "\n",
        "index_non_zero = -1\n",
        "for j in range(N):\n",
        "  #NB: valid e training\n",
        "  w_phi[j] = np.sum(np.array([c[i]*in_labels[i]*kernel_vec(valid[j, :], training[i, :]) for i in range(N)]))\n",
        "  if c[j]>0 and index_non_zero<0:\n",
        "    index_non_zero = j\n",
        "\n",
        "b = - in_labels[index_non_zero] + w_phi[index_non_zero]"
      ],
      "metadata": {
        "id": "H6eFQnPOgM1p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}